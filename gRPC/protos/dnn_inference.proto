syntax = "proto3";

package dnn_surgery;

// Represents a tensor shape
message TensorShape {
    repeated int32 dimensions = 1;
}

// Represents a tensor
message Tensor {
    bytes data = 1;  // Serialized tensor data
    TensorShape shape = 2;
    string dtype = 3;  // Data type (float32, float64, etc.)
    bool requires_grad = 4;
}

// Request from edge device with intermediate tensor
message InferenceRequest {
    Tensor tensor = 1;
    string model_id = 2;  // Identifier for which model/layer to start from
}

// Response from cloud with final output
message InferenceResponse {
    Tensor tensor = 1;
    bool success = 2;
    string error_message = 3;
    double server_execution_time_ms = 4;
    double server_total_time_ms = 5;
}

// Request for network bandwidth probing via gRPC
message BandwidthProbeRequest {
    string client_id = 1;
    bytes payload = 2;
}

// Response for network bandwidth probing via gRPC
message BandwidthProbeResponse {
    bool success = 1;
    string message = 2;
    double server_processing_time_ms = 3;
    bytes payload = 4;
}

// Layer profiling metrics from client hardware
message LayerProfile {
    int32 layer_idx = 1;
    string layer_name = 2;
    double execution_time = 3;  // milliseconds
    repeated int32 input_size = 4;
    repeated int32 output_size = 5;
    int64 data_transfer_size = 6;
}


// Complete client profiling data
message ClientProfile {
    string model_name = 1;
    repeated LayerProfile layer_metrics = 2;
    repeated int32 input_size = 4;
    int32 total_layers = 5;
}

// Request to send profiling data to server
message ProfilingRequest {
    ClientProfile profile = 1;
    string client_id = 2;  // Unique identifier for client
}

// Response after receiving profiling data
message ProfilingResponse {
    bool success = 1;
    string message = 2;
    string updated_split_config = 3;  // Optional: new split configuration
}

// Request to set split point (client decision)
message SplitConfigRequest {
    string model_name = 1;
    int32 split_point = 2;  // Client's optimal split point decision
}

// Response after setting split point
message SplitConfigResponse {
    bool success = 1;
    string message = 2;
}

// Service definition for DNN inference
service DNNInference {
    // Send intermediate tensor to cloud for further processing
    rpc ProcessTensor (InferenceRequest) returns (InferenceResponse) {}
    
    // Send client profiling data for optimal split calculation
    rpc SendProfilingData (ProfilingRequest) returns (ProfilingResponse) {}
    
    // Send client's split point decision to server
    rpc set_split_point (SplitConfigRequest) returns (SplitConfigResponse) {}

    // Round-trip payload to measure effective bandwidth/latency
    rpc MeasureBandwidth (BandwidthProbeRequest) returns (BandwidthProbeResponse) {}
}
